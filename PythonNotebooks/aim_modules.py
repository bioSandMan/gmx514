# General syntax to import a library but no functions: 
#import (library) as (give the library a nickname/alias)
import pandas as pd
from pandas import DataFrame, read_csv
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import re
import pickle
from scipy import stats


matplotlib.style.use('ggplot')

from scipy import stats

"""
Create a function that calculates AIM from the output of the log file

This output is generated by Gromacs with AIM in the log file.

  1  0.000  0.000    10448    0.00000   -0.02861  72.74402 -38.80195
  2  0.200  0.000    10246   -0.02861    0.03107  48.73083 -10.09811
  3  0.400  0.000    10864    0.00247   -0.02543  30.36052   4.23614
  4  0.600  0.000    10751   -0.02297   -0.04503  16.18198  11.43519
  5  0.800  0.000    10765   -0.06800   -0.06085   6.97454  13.26155
  6  1.000  0.000    10483   -0.12885    0.00558   0.18699  14.00396
  ...
  

For each log output I extract the output using bash cli:

for i in 1 2 3 4 5;
do;
$tail -135 out0$i.log | grep -A 21 " | tr -d '<<' >> aimgpu0$i.out;
done

I then moved the files over to my laptop and made sure the format was correct.

"""
def quad_AIM(file_in=None, names=None):
    df_allk = list(); ddf_allk = list()
    # import the copied averages from the AIM simu
    location = file_in
    myDeltaG = pd.read_csv(
        location, 
        header = None,
        names = names,
        delim_whitespace=True)

    # only need the average values from the copied info
    dGdcoul = myDeltaG.dGCoulL
    dGdvdw = myDeltaG.dGVdwL
    coulLambdas = myDeltaG.CoulL.values
    vdwLambdas = myDeltaG.VdwL.values

    # we only need the delta lambdas so we don't need a 2d array here
    dlamCoul = np.diff(coulLambdas, axis=0)
    dlamVdw = np.diff(vdwLambdas, axis=0)

    lv = []
    ave_dhdl = []
    for i in range(len(coulLambdas)):
        lv.append([coulLambdas[i], vdwLambdas[i]])
        ave_dhdl.append([dGdcoul[i], dGdvdw[i]])

    lv = np.array(lv)
    ave_dhdl = np.array(ave_dhdl)
    K, n_components = lv.shape
    lchange = get_lchange(lv, K, n_components)
    cubspl, mapl = getSplines(lchange, K, n_components, lv)

    dlam = []
    for i in range(len(dlamCoul)):
        dlam.append([dlamCoul[i], dlamVdw[i]])
    dlam = np.array(dlam)

    aim = 0.0
    aimcubic = 0.0
    aim_cubic = []
    aim_trapz = []
    for k in range(K-1):
        aim += (0.5*np.dot(dlam[k],(ave_dhdl[k]+ave_dhdl[k+1])))
        aim_trapz.append(0.5*np.dot(dlam[k],(ave_dhdl[k]+ave_dhdl[k+1])))
        for j in range(n_components):
            if dlam[k,j] > 0:
                lj = lchange[:,j]
                aimcubic += (np.dot(cubspl[j].wk[mapl[k,j]],ave_dhdl[lj,j]))
                aim_cubic.append(aimcubic)
    counts = myDeltaG.AIMCount         
    return(aim, aimcubic, counts, aim_trapz, aim_cubic, ave_dhdl, dGdcoul,
           dGdvdw, coulLambdas, vdwLambdas)

def hist_flatness(counts=None, sim_label=None, ymin=1, ymax=2):
    """
    Expects an array of counts and a label
    """
    ###############################################################################
    # Is it flat enough?  Is the minimum entry less than 80% of its average value?
    # It is common practice to consider a histogram "sufficiently flat" when its
    # minimum entry is no less than 80% of its average value.
    ###############################################################################
    dfnum = np.array(counts)
    flatness = 100*(min(dfnum)/np.average(dfnum))
    if flatness > 80:
        flat = "It's flat"
    else:
        flat = "Not flat"
        
    x = np.linspace(0,1,len(dfnum))
    # normalize the values
    y = [float(i)/dfnum.sum() for i in dfnum]
    plt.title("Lambda Histogram", fontsize=22)
    plt.grid(True)
    plt.grid(color='gray', linestyle='-', linewidth=0.2)
    plt.xlabel("Lambda Values", fontsize=22)
    plt.ylabel("AIM Count at Lambda", fontsize=22)
    plt.xlim(0,np.min(x)+0.5)
    plt.ylim(ymin,ymax)
    if sim_label is not None:
        plt.plot(x, y,label=sim_label)
        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))
    else:
        plt.plot(x, y)
    print(sim_label, " ", flat, flatness)
    return(plt)
    
# Taken without remorse from
# https://github.com/MobleyLab/alchemical-analysis/blob/master/alchemical_analysis/alchemical_analysis.py
class naturalcubicspline:

    def __init__(self, x):

        # define some space
        L = len(x)
        H = np.zeros([L,L],float)
        M = np.zeros([L,L],float)
        BW = np.zeros([L,L],float)
        AW = np.zeros([L,L],float)
        DW = np.zeros([L,L],float)

        h = x[1:L]-x[0:L-1]
        ih = 1.0/h

        # define the H and M matrix, from p. 371 "applied numerical methods with matlab, Chapra"
        H[0,0] = 1
        H[L-1,L-1] = 1
        for i in range(1,L-1):
            H[i,i] = 2*(h[i-1]+h[i])
            H[i,i-1] = h[i-1]
            H[i,i+1] = h[i]

            M[i,i] = -3*(ih[i-1]+ih[i])
            M[i,i-1] = 3*(ih[i-1])
            M[i,i+1] = 3*(ih[i])

        CW = np.dot(np.linalg.inv(H),M)  # this is the matrix translating c to weights in f.
                                                       # each row corresponds to the weights for each c.

        # from CW, define the other coefficient matrices
        for i in range(0,L-1):
            BW[i,:]    = -(h[i]/3)*(2*CW[i,:]+CW[i+1,:])
            BW[i,i]   += -ih[i]
            BW[i,i+1] += ih[i]
            DW[i,:]    = (ih[i]/3)*(CW[i+1,:]-CW[i,:])
            AW[i,i]    = 1

        # Make copies of the arrays we'll be using in the future.
        self.x  = x.copy()
        self.AW = AW.copy()
        self.BW = BW.copy()
        self.CW = CW.copy()
        self.DW = DW.copy()

        # find the integrating weights
        self.wsum = np.zeros([L],float)
        self.wk = np.zeros([L-1,L],float)
        for k in range(0,L-1):
            w = DW[k,:]*(h[k]**4)/4.0 + CW[k,:]*(h[k]**3)/3.0 + BW[k,:]*(h[k]**2)/2.0 + AW[k,:]*(h[k])
            self.wk[k,:] = w
            self.wsum += w

    def interpolate(self,y,xnew):
        if len(self.x) != len(y):
            parser.error("\nThe length of 'y' should be consistent with that of 'self.x'. I cannot perform linear algebra operations.")
        # get the array of actual coefficients by multiplying the coefficient matrix by the values
        a = np.dot(self.AW,y)
        b = np.dot(self.BW,y)
        c = np.dot(self.CW,y)
        d = np.dot(self.DW,y)

        N = len(xnew)
        ynew = np.zeros([N],float)
        for i in range(N):
            # Find the index of 'xnew[i]' it would have in 'self.x'.
            j = np.searchsorted(self.x, xnew[i]) - 1
            lamw = xnew[i] - self.x[j]
            ynew[i] = d[j]*lamw**3 + c[j]*lamw**2 + b[j]*lamw + a[j]
        # Preserve the terminal points.
        ynew[0] = y[0]
        ynew[-1] = y[-1]
        return ynew

def get_lchange(lv, K, n_components):
    lchange = np.zeros([K,n_components],bool)   # booleans for which lambdas are changing
    for j in range(n_components):
        # need to identify range over which lambda doesn't change, and not interpolate over that range.
        for k in range(K-1):
            if (lv[k+1,j]-lv[k,j] > 0):
                lchange[k,j] = True
                lchange[k+1,j] = True
    return lchange

def getSplines(lchange, K, n_components, lv):
    # construct a map back to the original components
    mapl = np.zeros([K,n_components],int)   # map back to the original k from the components
    for j in range(n_components):
        incr = 0
        for k in range(K):
            if (lchange[k,j]):
                mapl[k,j] += incr
                incr +=1

    # put together the spline weights for the different components
    cubspl = list()
    for j in range(n_components):
        lv_lchange = lv[lchange[:,j],j]
        if len(lv_lchange) == 0: # handle the all-zero lv column
            cubspl.append(0)
        else:
            spl = naturalcubicspline(lv_lchange)
            cubspl.append(spl)
    return cubspl, mapl

def import_pickle(root, runs, prefix):
    import pickle
    results = pd.DataFrame()
    for j in runs:
        # import the pickled resuls from pymbar
        location = root+"/{0}/{1}.pickle".format(j,prefix)
        with open(location, 'rb') as handle:
            unserialized_data = pickle.load(handle)

        # convert the values from k_BT to kJ/mol
        # store in a new dictionary
        new_dict = dict()
        for i in unserialized_data.dFs[2]:
             new_dict[i] = unserialized_data.dFs[2][i]*2.4947

        # place the values into a dataframe
        df = pd.DataFrame([new_dict], columns=new_dict.keys())
        results = pd.concat([results, df],ignore_index=True)
    return(results)

def plot_errorbars(results=None, save=False, save_file=None, ymin=20, ymax=22.5, exprmnt=20):
    """
    Expects a dataframe of values
    Use Pymbar to get the results
    make sure to skip half of the xvg file
    Command line was: /Users/ChrisM/anaconda/bin/alchemical_analysis -t 300 -x -v -p prod -s 500 -i 0

    Get the result from each run to look like this
    5 ns
            TI  TI-CUBIC DEXP    IEXP    BAR  MBAR    AIM
    run01 18.782 18.524 18.349 18.633 18.522 18.510 15.22232
    run02 18.776 18.496 18.398 18.538 18.535 18.561 15.34766
    run03 18.665 18.404 18.218 18.541 18.402 18.438 15.39739
    run04 18.679 18.410 18.382 18.594 18.417 18.471 15.20885
    run05 18.679 18.400 18.316 18.543 18.408 18.441 15.09506
    Plot the results using error bars for each lambda window 1ns, 5ns, 10ns
    """

    plt.close()
    labels = results.columns
    y = np.array(results.mean().values)
    x = range(len(y))
    plt.close()
    plt.xticks(x, labels, rotation='vertical')
    # Tweak spacing to prevent clipping of tick-labels
    plt.subplots_adjust(bottom=0.5)
    plt.ylabel("$\Delta$G (kcal/mol)", fontsize = 20)
    plt.xlabel('Method', fontsize = 20)
    plt.errorbar(x, y, yerr=stats.sem(results), fmt=None)
    plt.scatter(x, y)
    plt.ylim(ymin, ymax)

    # Create a simple legend
    plt.legend(loc=0, borderaxespad=0., fontsize=14, ncol=1)
    plt.style.use('ggplot')
    
    y_value = np.ones(len(x))*exprmnt
    plt.fill_between(x, y_value+0.3, y_value-0.3, alpha=.1)
    plt.plot(x, y_value)
    

    plt.show()
    if save:
        # Finally, save the figure as a png.  
        # You can also save it as a PDF, JPEG, etc.  
        # Just change the file extension in this call.  
        # bbox_inches="tight" removes all the extra whitespace on the edges of your plot.  
        plt.savefig(save_file+".png", bbox_inches="tight", dpi=300);

# plot acceptance as a function of steps
import pandas as pd
def getAcceptance(array):
    count = 0
    for i in range(len(array)-1):
        if array[i+1] != array[i]:
            count = count + 1
    return(float(count)/len(array)*100)

# convert kJ/mol to kcal/mol and vice-versa
# kj_mol = 1
# kcal_mol = 0.239006
# 1 kJ/mol = 0.239006 kcal/mol
# 4 kJ/mol = 0.96 kcal/mol

def convert_to_kcal(kj):
    return float(kj*0.239)

def convert_to_kj(kcal):
    return float(kcal/0.239)

def quad_TI(file_in=None, names=None, coulLambdas=[], vdwLambdas=[]):
    # import the copied averages from the AIM simu
    location = file_in
    myDeltaG = pd.read_csv(
        location, 
        header = None,
        names = names,
        delim_whitespace=True)

    # only need the average values from the copied info
    dGdcoul = myDeltaG.dGCoulL
    dGdvdw = myDeltaG.dGVdwL
    # we only need the delta lambdas so we don't need a 2d array here
    dlamCoul = np.diff(coulLambdas, axis=0)
    dlamVdw = np.diff(vdwLambdas, axis=0)

    lv = []
    ave_dhdl = []
    for i in range(len(coulLambdas)):
        lv.append([coulLambdas[i], vdwLambdas[i]])
        ave_dhdl.append([dGdcoul[i], dGdvdw[i]]) # unitless

    lv = np.array(lv)
    ave_dhdl = np.array(ave_dhdl)
    K, n_components = lv.shape
    lchange = get_lchange(lv, K, n_components)
    cubspl, mapl = getSplines(lchange, K, n_components, lv)

    dlam = []
    for i in range(len(dlamCoul)):
        dlam.append([dlamCoul[i], dlamVdw[i]])
    dlam = np.array(dlam)

    ti = 0
    ticubic = 0.0
    ti_cubic = []
    ti_trapz = []
    for k in range(K-1):
        ti += 0.5*np.dot(dlam[k],(ave_dhdl[k]+ave_dhdl[k+1]))
        ti_trapz.append(0.5*np.dot(dlam[k],(ave_dhdl[k]+ave_dhdl[k+1])))
        for j in range(n_components):
            if dlam[k,j] > 0:
                lj = lchange[:,j]
                ticubic += np.dot(cubspl[j].wk[mapl[k,j]],ave_dhdl[lj,j])   
                ti_cubic.append(ticubic)
    return(ti, ticubic, ti_trapz, ti_cubic, ave_dhdl, dGdcoul,
           dGdvdw)

def plotdFvsLambda1(df_allk, times, ymin, ymax, num_lambdas):
    """Plots the free energy differences evaluated for each pair of adjacent states for all methods."""
    x = np.arange(num_lambdas)
    fig = plt.figure(figsize = (len(x),6))
    width = 1./(len(times)+1)
    elw = 30*width
    colors = {'100ps':'#C45AEC', '250ps':'#33CC33', '500ps':'#F87431', '1ns':'#FF3030', '5ns':'#EAC117', '10ns':'#347235', 'AIM':'#6698FF', 'FIXED':'#817339'
             , 'AIM_coul':'#C45AEC', 'FIXED_coul':'#33CC33', 'AIM_vdw':'#F87431','FIXED_vdw':'#FF3030'}
    lines = tuple()
    for time in times:
        y = [df_allk[time][i] for i in x]
        #ye = [ddf_allk[i][name] for i in x]
        #line = plt.bar(x+len(lines)*width, y, width, color=colors[name], yerr=ye, lw=0.1*elw, error_kw=dict(elinewidth=elw, ecolor='black', capsize=0.5*elw))
        #plt.plot(x, y, color=colors[time], lw=0.1*elw)
        line = plt.bar(x+len(lines)*width, y, width, color=colors[time], lw=0.1*elw)
        lines += (line[0],)
    plt.xlabel('$\lambda$ States', fontsize=12, color='#151B54')
    plt.ylabel('$\Delta G$ (kJ/mol)', fontsize=12, color='#151B54')
    plt.xticks(x+0.5*width*len(times), tuple(['%d--%d' % (i, i+1) for i in x]), fontsize=8)
    plt.yticks(fontsize=8)
    plt.xlim(x[0], x[-1]+len(lines)*width)
    plt.ylim(ymin,ymax)
    ax = plt.gca()
    for dir in ['right', 'top', 'bottom']:
        ax.spines[dir].set_color('none')
    ax.yaxis.set_ticks_position('left')
    for tick in ax.get_xticklines():
        tick.set_visible(False)

    leg = plt.legend(lines, tuple(times), loc=3, ncol=2, fancybox=True)
    leg.get_frame().set_alpha(0.5)
    plt.title('The free energy change breakdown', fontsize = 12)
    #pl.savefig(os.path.join(P.output_directory, 'dF_state_long.pdf'), bbox_inches='tight')
    #pl.close(fig)
    plt.show()
    return

def plotdFvsLambda2(df_allk, times, ymin, ymax, num_lambdas):
    """Plots the free energy differences evaluated for each pair of adjacent states for all methods."""
    x = np.arange(num_lambdas)
    fig = plt.figure(figsize = (len(x),6))
    width = 1./(len(times)+1)
    elw = 30*width
    colors = {'100ps':'#C45AEC', '250ps':'#33CC33', '500ps':'#F87431', '1ns':'#FF3030', '5ns':'#EAC117', '10ns':'#347235', 'AIM':'#6698FF', 'FIXED':'#817339'
             , 'AIM_coul':'#C45AEC', 'FIXED_coul':'#33CC33', 'AIM_vdw':'#F87431','FIXED_vdw':'#FF3030'}
    lines = tuple()
    for time in times:
        y = [df_allk[time][i] for i in x]
        #ye = [ddf_allk[i][name] for i in x]
        #line = plt.bar(x+len(lines)*width, y, width, color=colors[name], yerr=ye, lw=0.1*elw, error_kw=dict(elinewidth=elw, ecolor='black', capsize=0.5*elw))
        #plt.plot(x, y, color=colors[time], lw=0.1*elw)
        line = plt.bar(x+len(lines)*width, y, width, color=colors[time], lw=0.1*elw)
        lines += (line[0],)
    plt.xlabel('$\lambda$ States', fontsize=12, color='#151B54')
    plt.ylabel(r'$\langle{\frac{ \partial U } { \partial \lambda }}\rangle_{\lambda}$', fontsize=12, color='#151B54')
    plt.xticks(x+0.5*width*len(times), tuple(['%d' % (i) for i in x]), fontsize=8)
    plt.yticks(fontsize=8)
    plt.xlim(x[0], x[-1]+len(lines)*width)
    plt.ylim(ymin,ymax)
    ax = plt.gca()
    for dir in ['right', 'top', 'bottom']:
        ax.spines[dir].set_color('none')
    ax.yaxis.set_ticks_position('left')
    for tick in ax.get_xticklines():
        tick.set_visible(False)

    leg = plt.legend(lines, tuple(times), loc=3, ncol=2, fancybox=True)
    leg.get_frame().set_alpha(0.5)
    plt.title('The dhdl breakdown', fontsize = 12)
    #pl.savefig(os.path.join(P.output_directory, 'dF_state_long.pdf'), bbox_inches='tight')
    #pl.close(fig)
    plt.show()
    return

def calc_nsteps(dt,num_lambdas,ns_perLambda):
    """
    Reference:
    If dt = 0.001,
    if you want 1ns per lambda
    and you have 21 lambdas,
    then nsteps = 21000000 ; 1 ns per lambda

    If you are just running a normal sim then 
    num_lambdas = 1

    Usage:

    # time step
    dt = 0.002

    # how many lambdas?
    # 1 if running normal sims
    num_lambdas = 1

    # how many ns per lambda? CHANGE THIS!!!
    # 500 ps = 0.5 ns, 250 ps = 0.25 ns
    # unit is ns
    ns_per_lambda = 0.1

    calc_nsteps(dt, num_lambdas, ns_per_lambda)

    out: 50000.0
    """
    # steps = ?
    # 1000 ps = 1 ns
    factor = 1000
    # want the answer in # of steps
    return num_lambdas*ns_perLambda*factor/dt
